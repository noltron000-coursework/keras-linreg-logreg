{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes ~ Diagnosis Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for dataframe manipulation.\n",
    "import pandas\n",
    "\n",
    "# This is for special high-efficiency arrays.\n",
    "import numpy\n",
    "\n",
    "# This is for plotting data-points.\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "# These various imports will be explained as they are used later.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in dataset\n",
    "data = pandas.read_csv('./data/diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome\n",
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = data.loc[:, ['Outcome']]\n",
    "X = data.drop(columns=['Outcome'])\n",
    "\n",
    "display(X.head())\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8)\n",
      "(192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05882353, 1.00505051, 0.62295082, ..., 0.63934426, 0.56191289,\n",
       "        0.01666667],\n",
       "       [0.11764706, 0.54040404, 0.60655738, ..., 0.50074516, 0.13919727,\n",
       "        0.03333333],\n",
       "       [0.23529412, 0.38383838, 0.50819672, ..., 0.50670641, 0.13364646,\n",
       "        0.06666667],\n",
       "       ...,\n",
       "       [0.05882353, 0.55050505, 0.49180328, ..., 0.37853949, 0.37105038,\n",
       "        0.        ],\n",
       "       [0.17647059, 0.64646465, 0.63934426, ..., 0.31445604, 0.08112724,\n",
       "        0.56666667],\n",
       "       [0.29411765, 0.44444444, 0.63934426, ..., 0.41132638, 0.07685739,\n",
       "        0.26666667]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = MinMaxScaler()\n",
    "X_scaled.fit(X_train)\n",
    "X_scaled.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = 8, kernel_initializer='normal'))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 460 samples, validate on 116 samples\n",
      "Epoch 1/150\n",
      "460/460 [==============================] - 0s 600us/step - loss: 0.7475 - acc: 0.3674 - val_loss: 0.7172 - val_acc: 0.3276\n",
      "Epoch 2/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.7010 - acc: 0.4326 - val_loss: 0.6925 - val_acc: 0.5690\n",
      "Epoch 3/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6908 - acc: 0.6130 - val_loss: 0.6877 - val_acc: 0.6810\n",
      "Epoch 4/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6882 - acc: 0.6239 - val_loss: 0.6839 - val_acc: 0.6810\n",
      "Epoch 5/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6857 - acc: 0.6326 - val_loss: 0.6809 - val_acc: 0.6810\n",
      "Epoch 6/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6832 - acc: 0.6326 - val_loss: 0.6772 - val_acc: 0.6810\n",
      "Epoch 7/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6799 - acc: 0.6326 - val_loss: 0.6713 - val_acc: 0.6810\n",
      "Epoch 8/150\n",
      "460/460 [==============================] - 0s 34us/step - loss: 0.6744 - acc: 0.6326 - val_loss: 0.6662 - val_acc: 0.6810\n",
      "Epoch 9/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6680 - acc: 0.6326 - val_loss: 0.6451 - val_acc: 0.6810\n",
      "Epoch 10/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6585 - acc: 0.6326 - val_loss: 0.6282 - val_acc: 0.6810\n",
      "Epoch 11/150\n",
      "460/460 [==============================] - 0s 33us/step - loss: 0.6614 - acc: 0.6326 - val_loss: 0.6277 - val_acc: 0.6810\n",
      "Epoch 12/150\n",
      "460/460 [==============================] - 0s 33us/step - loss: 0.6582 - acc: 0.6326 - val_loss: 0.6317 - val_acc: 0.6810\n",
      "Epoch 13/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6517 - acc: 0.6326 - val_loss: 0.6380 - val_acc: 0.6810\n",
      "Epoch 14/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6490 - acc: 0.6326 - val_loss: 0.6307 - val_acc: 0.6810\n",
      "Epoch 15/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6441 - acc: 0.6326 - val_loss: 0.6238 - val_acc: 0.6810\n",
      "Epoch 16/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6428 - acc: 0.6326 - val_loss: 0.6229 - val_acc: 0.6810\n",
      "Epoch 17/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6417 - acc: 0.6326 - val_loss: 0.6238 - val_acc: 0.6810\n",
      "Epoch 18/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6424 - acc: 0.6326 - val_loss: 0.6291 - val_acc: 0.6810\n",
      "Epoch 19/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6393 - acc: 0.6326 - val_loss: 0.6246 - val_acc: 0.6810\n",
      "Epoch 20/150\n",
      "460/460 [==============================] - 0s 38us/step - loss: 0.6373 - acc: 0.6326 - val_loss: 0.6196 - val_acc: 0.6810\n",
      "Epoch 21/150\n",
      "460/460 [==============================] - 0s 36us/step - loss: 0.6387 - acc: 0.6326 - val_loss: 0.6175 - val_acc: 0.6810\n",
      "Epoch 22/150\n",
      "460/460 [==============================] - 0s 41us/step - loss: 0.6370 - acc: 0.6326 - val_loss: 0.6210 - val_acc: 0.6810\n",
      "Epoch 23/150\n",
      "460/460 [==============================] - 0s 38us/step - loss: 0.6354 - acc: 0.6326 - val_loss: 0.6163 - val_acc: 0.6810\n",
      "Epoch 24/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6350 - acc: 0.6326 - val_loss: 0.6229 - val_acc: 0.6810\n",
      "Epoch 25/150\n",
      "460/460 [==============================] - 0s 33us/step - loss: 0.6321 - acc: 0.6326 - val_loss: 0.6206 - val_acc: 0.6810\n",
      "Epoch 26/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6327 - acc: 0.6326 - val_loss: 0.6236 - val_acc: 0.6810\n",
      "Epoch 27/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6305 - acc: 0.6326 - val_loss: 0.6179 - val_acc: 0.6810\n",
      "Epoch 28/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6305 - acc: 0.6326 - val_loss: 0.6198 - val_acc: 0.6810\n",
      "Epoch 29/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6300 - acc: 0.6326 - val_loss: 0.6219 - val_acc: 0.6810\n",
      "Epoch 30/150\n",
      "460/460 [==============================] - 0s 39us/step - loss: 0.6295 - acc: 0.6326 - val_loss: 0.6175 - val_acc: 0.6810\n",
      "Epoch 31/150\n",
      "460/460 [==============================] - 0s 35us/step - loss: 0.6277 - acc: 0.6326 - val_loss: 0.6160 - val_acc: 0.6810\n",
      "Epoch 32/150\n",
      "460/460 [==============================] - 0s 37us/step - loss: 0.6261 - acc: 0.6326 - val_loss: 0.6185 - val_acc: 0.6810\n",
      "Epoch 33/150\n",
      "460/460 [==============================] - 0s 35us/step - loss: 0.6254 - acc: 0.6326 - val_loss: 0.6153 - val_acc: 0.6810\n",
      "Epoch 34/150\n",
      "460/460 [==============================] - 0s 36us/step - loss: 0.6240 - acc: 0.6326 - val_loss: 0.6189 - val_acc: 0.6810\n",
      "Epoch 35/150\n",
      "460/460 [==============================] - 0s 33us/step - loss: 0.6229 - acc: 0.6326 - val_loss: 0.6133 - val_acc: 0.6810\n",
      "Epoch 36/150\n",
      "460/460 [==============================] - 0s 35us/step - loss: 0.6239 - acc: 0.6326 - val_loss: 0.6154 - val_acc: 0.6810\n",
      "Epoch 37/150\n",
      "460/460 [==============================] - 0s 34us/step - loss: 0.6239 - acc: 0.6326 - val_loss: 0.6176 - val_acc: 0.6810\n",
      "Epoch 38/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6212 - acc: 0.6326 - val_loss: 0.6139 - val_acc: 0.6810\n",
      "Epoch 39/150\n",
      "460/460 [==============================] - 0s 39us/step - loss: 0.6196 - acc: 0.6326 - val_loss: 0.6189 - val_acc: 0.6810\n",
      "Epoch 40/150\n",
      "460/460 [==============================] - 0s 33us/step - loss: 0.6220 - acc: 0.6326 - val_loss: 0.6179 - val_acc: 0.6810\n",
      "Epoch 41/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6189 - acc: 0.6326 - val_loss: 0.6169 - val_acc: 0.6810\n",
      "Epoch 42/150\n",
      "460/460 [==============================] - 0s 33us/step - loss: 0.6185 - acc: 0.6326 - val_loss: 0.6119 - val_acc: 0.6810\n",
      "Epoch 43/150\n",
      "460/460 [==============================] - 0s 34us/step - loss: 0.6187 - acc: 0.6326 - val_loss: 0.6156 - val_acc: 0.6810\n",
      "Epoch 44/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6165 - acc: 0.6326 - val_loss: 0.6168 - val_acc: 0.6810\n",
      "Epoch 45/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.6160 - acc: 0.6326 - val_loss: 0.6170 - val_acc: 0.6810\n",
      "Epoch 46/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.6157 - acc: 0.6326 - val_loss: 0.6169 - val_acc: 0.6810\n",
      "Epoch 47/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.6142 - acc: 0.6326 - val_loss: 0.6157 - val_acc: 0.6810\n",
      "Epoch 48/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6140 - acc: 0.6326 - val_loss: 0.6165 - val_acc: 0.6810\n",
      "Epoch 49/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6131 - acc: 0.6326 - val_loss: 0.6183 - val_acc: 0.6810\n",
      "Epoch 50/150\n",
      "460/460 [==============================] - 0s 35us/step - loss: 0.6129 - acc: 0.6326 - val_loss: 0.6180 - val_acc: 0.6810\n",
      "Epoch 51/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6173 - acc: 0.6326 - val_loss: 0.6167 - val_acc: 0.6810\n",
      "Epoch 52/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6124 - acc: 0.6326 - val_loss: 0.6177 - val_acc: 0.6810\n",
      "Epoch 53/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6124 - acc: 0.6326 - val_loss: 0.6156 - val_acc: 0.6810\n",
      "Epoch 54/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6117 - acc: 0.6326 - val_loss: 0.6185 - val_acc: 0.6810\n",
      "Epoch 55/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6107 - acc: 0.6326 - val_loss: 0.6205 - val_acc: 0.6810\n",
      "Epoch 56/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6094 - acc: 0.6326 - val_loss: 0.6177 - val_acc: 0.6810\n",
      "Epoch 57/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6089 - acc: 0.6326 - val_loss: 0.6202 - val_acc: 0.6810\n",
      "Epoch 58/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6097 - acc: 0.6326 - val_loss: 0.6177 - val_acc: 0.6810\n",
      "Epoch 59/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.6093 - acc: 0.6326 - val_loss: 0.6155 - val_acc: 0.6810\n",
      "Epoch 60/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.6091 - acc: 0.6326 - val_loss: 0.6227 - val_acc: 0.6810\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 31us/step - loss: 0.6072 - acc: 0.6326 - val_loss: 0.6171 - val_acc: 0.6810\n",
      "Epoch 62/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6065 - acc: 0.6326 - val_loss: 0.6178 - val_acc: 0.6810\n",
      "Epoch 63/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6054 - acc: 0.6326 - val_loss: 0.6200 - val_acc: 0.6810\n",
      "Epoch 64/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.6050 - acc: 0.6326 - val_loss: 0.6222 - val_acc: 0.6810\n",
      "Epoch 65/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6050 - acc: 0.6326 - val_loss: 0.6206 - val_acc: 0.6810\n",
      "Epoch 66/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6054 - acc: 0.6326 - val_loss: 0.6219 - val_acc: 0.6810\n",
      "Epoch 67/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.6054 - acc: 0.6326 - val_loss: 0.6197 - val_acc: 0.6810\n",
      "Epoch 68/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.6031 - acc: 0.6326 - val_loss: 0.6223 - val_acc: 0.6810\n",
      "Epoch 69/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6019 - acc: 0.6326 - val_loss: 0.6221 - val_acc: 0.6810\n",
      "Epoch 70/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.6017 - acc: 0.6326 - val_loss: 0.6220 - val_acc: 0.6810\n",
      "Epoch 71/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6039 - acc: 0.6326 - val_loss: 0.6277 - val_acc: 0.6810\n",
      "Epoch 72/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.6009 - acc: 0.6326 - val_loss: 0.6174 - val_acc: 0.6810\n",
      "Epoch 73/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.6029 - acc: 0.6326 - val_loss: 0.6208 - val_acc: 0.6810\n",
      "Epoch 74/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.5998 - acc: 0.6326 - val_loss: 0.6219 - val_acc: 0.6810\n",
      "Epoch 75/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5989 - acc: 0.6326 - val_loss: 0.6219 - val_acc: 0.6810\n",
      "Epoch 76/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5990 - acc: 0.6326 - val_loss: 0.6221 - val_acc: 0.6810\n",
      "Epoch 77/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5988 - acc: 0.6326 - val_loss: 0.6238 - val_acc: 0.6810\n",
      "Epoch 78/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5979 - acc: 0.6326 - val_loss: 0.6232 - val_acc: 0.6810\n",
      "Epoch 79/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5987 - acc: 0.6326 - val_loss: 0.6224 - val_acc: 0.6810\n",
      "Epoch 80/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5972 - acc: 0.6326 - val_loss: 0.6279 - val_acc: 0.6810\n",
      "Epoch 81/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.6031 - acc: 0.6326 - val_loss: 0.6296 - val_acc: 0.6810\n",
      "Epoch 82/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5986 - acc: 0.6326 - val_loss: 0.6183 - val_acc: 0.6810\n",
      "Epoch 83/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.5987 - acc: 0.6326 - val_loss: 0.6267 - val_acc: 0.6810\n",
      "Epoch 84/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5969 - acc: 0.6326 - val_loss: 0.6275 - val_acc: 0.6810\n",
      "Epoch 85/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.6019 - acc: 0.6543 - val_loss: 0.6231 - val_acc: 0.7241\n",
      "Epoch 86/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5938 - acc: 0.6587 - val_loss: 0.6306 - val_acc: 0.6724\n",
      "Epoch 87/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5967 - acc: 0.6587 - val_loss: 0.6269 - val_acc: 0.6897\n",
      "Epoch 88/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5948 - acc: 0.6587 - val_loss: 0.6259 - val_acc: 0.6810\n",
      "Epoch 89/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5973 - acc: 0.6587 - val_loss: 0.6277 - val_acc: 0.6724\n",
      "Epoch 90/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5943 - acc: 0.6565 - val_loss: 0.6326 - val_acc: 0.6293\n",
      "Epoch 91/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5968 - acc: 0.6652 - val_loss: 0.6285 - val_acc: 0.6724\n",
      "Epoch 92/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5959 - acc: 0.6587 - val_loss: 0.6238 - val_acc: 0.6810\n",
      "Epoch 93/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5936 - acc: 0.6587 - val_loss: 0.6298 - val_acc: 0.6724\n",
      "Epoch 94/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5935 - acc: 0.6609 - val_loss: 0.6280 - val_acc: 0.6724\n",
      "Epoch 95/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.5945 - acc: 0.6565 - val_loss: 0.6269 - val_acc: 0.6724\n",
      "Epoch 96/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5969 - acc: 0.6587 - val_loss: 0.6347 - val_acc: 0.6293\n",
      "Epoch 97/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5991 - acc: 0.6652 - val_loss: 0.6317 - val_acc: 0.6293\n",
      "Epoch 98/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5906 - acc: 0.6652 - val_loss: 0.6216 - val_acc: 0.7069\n",
      "Epoch 99/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5956 - acc: 0.6652 - val_loss: 0.6281 - val_acc: 0.6810\n",
      "Epoch 100/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5947 - acc: 0.6630 - val_loss: 0.6353 - val_acc: 0.6466\n",
      "Epoch 101/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.5921 - acc: 0.6609 - val_loss: 0.6266 - val_acc: 0.6724\n",
      "Epoch 102/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5915 - acc: 0.6543 - val_loss: 0.6307 - val_acc: 0.6724\n",
      "Epoch 103/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5943 - acc: 0.6870 - val_loss: 0.6345 - val_acc: 0.6379\n",
      "Epoch 104/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5910 - acc: 0.6543 - val_loss: 0.6257 - val_acc: 0.6983\n",
      "Epoch 105/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5915 - acc: 0.6478 - val_loss: 0.6295 - val_acc: 0.6810\n",
      "Epoch 106/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5908 - acc: 0.6478 - val_loss: 0.6285 - val_acc: 0.6897\n",
      "Epoch 107/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5956 - acc: 0.6957 - val_loss: 0.6361 - val_acc: 0.6638\n",
      "Epoch 108/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5899 - acc: 0.6804 - val_loss: 0.6255 - val_acc: 0.6897\n",
      "Epoch 109/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5944 - acc: 0.6565 - val_loss: 0.6301 - val_acc: 0.6810\n",
      "Epoch 110/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5894 - acc: 0.6935 - val_loss: 0.6339 - val_acc: 0.6379\n",
      "Epoch 111/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5884 - acc: 0.6891 - val_loss: 0.6313 - val_acc: 0.6810\n",
      "Epoch 112/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.5878 - acc: 0.6826 - val_loss: 0.6309 - val_acc: 0.6810\n",
      "Epoch 113/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.5862 - acc: 0.6804 - val_loss: 0.6277 - val_acc: 0.6983\n",
      "Epoch 114/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5906 - acc: 0.6935 - val_loss: 0.6340 - val_acc: 0.6552\n",
      "Epoch 115/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.5858 - acc: 0.6978 - val_loss: 0.6295 - val_acc: 0.6810\n",
      "Epoch 116/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5873 - acc: 0.6609 - val_loss: 0.6284 - val_acc: 0.6897\n",
      "Epoch 117/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5860 - acc: 0.6935 - val_loss: 0.6340 - val_acc: 0.6724\n",
      "Epoch 118/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5884 - acc: 0.7109 - val_loss: 0.6335 - val_acc: 0.6724\n",
      "Epoch 119/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5863 - acc: 0.7109 - val_loss: 0.6308 - val_acc: 0.6810\n",
      "Epoch 120/150\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.5851 - acc: 0.6957 - val_loss: 0.6289 - val_acc: 0.6897\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 29us/step - loss: 0.5843 - acc: 0.6978 - val_loss: 0.6306 - val_acc: 0.6897\n",
      "Epoch 122/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5850 - acc: 0.7130 - val_loss: 0.6295 - val_acc: 0.6897\n",
      "Epoch 123/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5831 - acc: 0.7000 - val_loss: 0.6272 - val_acc: 0.6897\n",
      "Epoch 124/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5844 - acc: 0.6913 - val_loss: 0.6302 - val_acc: 0.6897\n",
      "Epoch 125/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5832 - acc: 0.7043 - val_loss: 0.6284 - val_acc: 0.6897\n",
      "Epoch 126/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5836 - acc: 0.6935 - val_loss: 0.6276 - val_acc: 0.6810\n",
      "Epoch 127/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5830 - acc: 0.6913 - val_loss: 0.6268 - val_acc: 0.6983\n",
      "Epoch 128/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.5820 - acc: 0.7043 - val_loss: 0.6251 - val_acc: 0.6810\n",
      "Epoch 129/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5829 - acc: 0.7022 - val_loss: 0.6233 - val_acc: 0.6897\n",
      "Epoch 130/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5843 - acc: 0.7065 - val_loss: 0.6289 - val_acc: 0.6466\n",
      "Epoch 131/150\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.5825 - acc: 0.6891 - val_loss: 0.6245 - val_acc: 0.6897\n",
      "Epoch 132/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5831 - acc: 0.6957 - val_loss: 0.6297 - val_acc: 0.6724\n",
      "Epoch 133/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5803 - acc: 0.7152 - val_loss: 0.6285 - val_acc: 0.6810\n",
      "Epoch 134/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5813 - acc: 0.7174 - val_loss: 0.6299 - val_acc: 0.6724\n",
      "Epoch 135/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5805 - acc: 0.7109 - val_loss: 0.6272 - val_acc: 0.6810\n",
      "Epoch 136/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5802 - acc: 0.7087 - val_loss: 0.6295 - val_acc: 0.6810\n",
      "Epoch 137/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5799 - acc: 0.7043 - val_loss: 0.6252 - val_acc: 0.6897\n",
      "Epoch 138/150\n",
      "460/460 [==============================] - 0s 25us/step - loss: 0.5809 - acc: 0.7022 - val_loss: 0.6285 - val_acc: 0.6810\n",
      "Epoch 139/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5833 - acc: 0.7239 - val_loss: 0.6338 - val_acc: 0.6379\n",
      "Epoch 140/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5808 - acc: 0.7000 - val_loss: 0.6220 - val_acc: 0.7155\n",
      "Epoch 141/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5799 - acc: 0.7043 - val_loss: 0.6309 - val_acc: 0.6724\n",
      "Epoch 142/150\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.5792 - acc: 0.7109 - val_loss: 0.6282 - val_acc: 0.6897\n",
      "Epoch 143/150\n",
      "460/460 [==============================] - 0s 29us/step - loss: 0.5802 - acc: 0.7043 - val_loss: 0.6303 - val_acc: 0.6638\n",
      "Epoch 144/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5793 - acc: 0.7043 - val_loss: 0.6262 - val_acc: 0.6897\n",
      "Epoch 145/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5792 - acc: 0.7109 - val_loss: 0.6295 - val_acc: 0.6810\n",
      "Epoch 146/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5780 - acc: 0.7087 - val_loss: 0.6281 - val_acc: 0.6724\n",
      "Epoch 147/150\n",
      "460/460 [==============================] - 0s 28us/step - loss: 0.5776 - acc: 0.7087 - val_loss: 0.6213 - val_acc: 0.6983\n",
      "Epoch 148/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5826 - acc: 0.7022 - val_loss: 0.6223 - val_acc: 0.6810\n",
      "Epoch 149/150\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.5787 - acc: 0.7022 - val_loss: 0.6235 - val_acc: 0.6724\n",
      "Epoch 150/150\n",
      "460/460 [==============================] - 0s 31us/step - loss: 0.5763 - acc: 0.7152 - val_loss: 0.6223 - val_acc: 0.7155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2ae42e50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_predict = model.predict(X_test)\n",
    "figure, axis = pyplot.subplots()\n",
    "\n",
    "axis.scatter(Y_test, Y_predict)\n",
    "axis.plot(\n",
    "\t[Y_test.min(), Y_test.max()],\n",
    "\t[Y_test.min(), Y_test.max()],\n",
    "\t'k--', lw=4\n",
    ")\n",
    "axis.set_xlabel('Measured')\n",
    "axis.set_ylabel('Predicted')\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
